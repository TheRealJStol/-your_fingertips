{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f06f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jared\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading zero‑shot model … "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# math_graph_prereq_noP361.py  – subclass/instance + MSC only\n",
    "\n",
    "# —————————————————— imports\n",
    "import os, time, itertools, pickle, functools, re, requests, networkx as nx\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# —————————————————— zero‑shot maths gatekeeper\n",
    "print(\"loading zero‑shot model … \", end=\"\", flush=True)\n",
    "zero_shot = pipeline(\"zero-shot-classification\",\n",
    "                     model=\"valhalla/distilbart-mnli-12-3\",\n",
    "                     device=-1)          # CPU\n",
    "print(\"done.\")\n",
    "\n",
    "CANDIDATES = [\"mathematics\", \"not mathematics\"]\n",
    "\n",
    "@functools.lru_cache(maxsize=8192)\n",
    "def is_math(label: str) -> bool:\n",
    "    s = label.lower()\n",
    "    if re.search(r\"\\b(algebra|geometry|calculus|number theory|mathem)\", s):\n",
    "        return True\n",
    "    if re.search(r\"\\b(music|film|politic|football|chemical|history)\", s):\n",
    "        return False\n",
    "    return zero_shot(label, CANDIDATES)[\"labels\"][0] == \"mathematics\"\n",
    "\n",
    "# —————————————————— crawl params\n",
    "SPARQL   = \"https://query.wikidata.org/sparql\"\n",
    "HEADERS  = {\"User-Agent\": \"MathGraph-NoP361/1.0\"}\n",
    "ROOTS    = [\"Q395\"]          # mathematics\n",
    "CHUNK    = 100; PAUSE = 0.1; MAX_NODES = 8000\n",
    "\n",
    "def sparql(q):  # helper\n",
    "    r = requests.post(SPARQL, data={\"query\": q, \"format\": \"json\"},\n",
    "                      headers=HEADERS, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"results\"][\"bindings\"]\n",
    "\n",
    "def batches(seq, n):\n",
    "    it = iter(seq)\n",
    "    while (chunk := list(itertools.islice(it, n))):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c784864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‣ BFS crawl …\n",
      "  + 51  (total 52)\n",
      "  + 98  (total 150)\n",
      "  + 52  (total 202)\n",
      "  +  9  (total 211)\n",
      "  +  3  (total 214)\n",
      "  +  0  (total 214)\n",
      "✔ Stage 1 nodes: 214\n"
     ]
    }
   ],
   "source": [
    "# —————————————————— Stage 1: BFS on P279/P31\n",
    "nodes, frontier = set(ROOTS), set(ROOTS)\n",
    "print(\"\\n‣ BFS crawl …\")\n",
    "while frontier and len(nodes) < MAX_NODES:\n",
    "    nxt = set()\n",
    "    for chunk in batches(frontier, CHUNK):\n",
    "        vals = \" \".join(f\"wd:{q}\" for q in chunk)\n",
    "        q = f\"\"\"\n",
    "        SELECT ?child ?childLabel WHERE {{\n",
    "          VALUES ?parent {{ {vals} }}\n",
    "          ?child (wdt:P279|wdt:P31) ?parent .\n",
    "          SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\" }}\n",
    "        }}\"\"\"\n",
    "        for row in sparql(q):\n",
    "            cid, lab = row[\"child\"][\"value\"].split(\"/\")[-1], row[\"childLabel\"][\"value\"]\n",
    "            if cid not in nodes and is_math(lab):\n",
    "                nodes.add(cid); nxt.add(cid)\n",
    "        time.sleep(PAUSE)\n",
    "    print(f\"  +{len(nxt):3}  (total {len(nodes)})\"); frontier = nxt\n",
    "print(f\"✔ Stage 1 nodes: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b3b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Stage 2 raw edges: 391\n"
     ]
    }
   ],
   "source": [
    "# ───── Stage 2 – collect ALL P279 / P31 edges (no dropping) ──────\n",
    "raw_edges = set()\n",
    "for chunk in batches(nodes, CHUNK):\n",
    "    vals = \" \".join(f\"wd:{q}\" for q in chunk)\n",
    "    q = f\"\"\"\n",
    "    SELECT ?p ?c ?rel WHERE {{\n",
    "      VALUES ?p {{ {vals} }}\n",
    "      ?p ?rel ?c .\n",
    "      FILTER(?rel IN (wdt:P279, wdt:P31))\n",
    "    }}\"\"\"\n",
    "    for r in sparql(q):\n",
    "        parent = r[\"p\"][\"value\"].rsplit(\"/\", 1)[-1]\n",
    "        child  = r[\"c\"][\"value\"].rsplit(\"/\", 1)[-1]\n",
    "        prop   = r[\"rel\"][\"value\"].rsplit(\"/\", 1)[-1]   # P279 or P31\n",
    "        raw_edges.add((parent, child, prop))\n",
    "    time.sleep(PAUSE)\n",
    "\n",
    "print(f\"✔ Stage 2 raw edges: {len(raw_edges)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3408da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ labels: 188\n"
     ]
    }
   ],
   "source": [
    "# —————————————————— Stage 3: labels\n",
    "labels = {}\n",
    "for chunk in batches(nodes, 200):\n",
    "    vals = \" \".join(f\"wd:{q}\" for q in chunk)\n",
    "    q = f\"\"\"\n",
    "    SELECT ?id ?label WHERE {{\n",
    "      VALUES ?id {{ {vals} }}\n",
    "      ?id rdfs:label ?label .\n",
    "      FILTER(lang(?label)=\"en\")\n",
    "    }}\"\"\"\n",
    "    for r in sparql(q):\n",
    "        labels[r[\"id\"][\"value\"].split(\"/\")[-1]] = r[\"label\"][\"value\"]\n",
    "    time.sleep(PAUSE)\n",
    "print(f\"✔ labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce8d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  enrich pass 1: +389 edges, 225 nodes\n",
      "  enrich pass 2: +572 edges, 393 nodes\n",
      "  enrich pass 3: +910 edges, 541 nodes\n",
      "  enrich pass 4: +1427 edges, 848 nodes\n",
      "  enrich pass 5: +2503 edges, 1500 nodes\n"
     ]
    }
   ],
   "source": [
    "# —————————————————— Stage 4: enrichment (P279 both ways)\n",
    "def enrich(snapshot):\n",
    "    extra = []\n",
    "    for chunk in batches(snapshot, CHUNK):\n",
    "        vals = \" \".join(f\"wd:{q}\" for q in chunk)\n",
    "        q = f\"\"\"\n",
    "        SELECT ?a ?b ?bLabel WHERE {{\n",
    "          VALUES ?a {{ {vals} }}\n",
    "          {{ ?a wdt:P279 ?b. }}\n",
    "          UNION\n",
    "          {{ ?b wdt:P279 ?a. }}\n",
    "          SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\" }}\n",
    "        }}\"\"\"\n",
    "        for r in sparql(q):\n",
    "            a = r[\"a\"][\"value\"].split(\"/\")[-1]\n",
    "            b = r[\"b\"][\"value\"].split(\"/\")[-1]\n",
    "            lab = r.get(\"bLabel\", {}).get(\"value\",\"\")\n",
    "            if b in nodes or (lab and is_math(lab)):\n",
    "                if b not in nodes:\n",
    "                    nodes.add(b); labels[b] = lab or b\n",
    "                extra.append((a,b,\"P279\"))\n",
    "        time.sleep(PAUSE)\n",
    "    return extra\n",
    "\n",
    "loop=0\n",
    "while True:\n",
    "    loop+=1; snap=list(nodes)\n",
    "    new = enrich(snap)\n",
    "    if not new: break\n",
    "    raw_edges.update(new)\n",
    "    print(f\"  enrich pass {loop}: +{len(new)} edges, {len(nodes)} nodes\")\n",
    "\n",
    "print(f\"✔ after enrichment: {len(nodes)} nodes, {len(raw_edges)} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————— Stage 5: MSC glue edges\n",
    "msc_edges=[]\n",
    "for chunk in batches(nodes, CHUNK):\n",
    "    vals=\" \".join(f\"wd:{q}\" for q in chunk)\n",
    "    q=f\"\"\"\n",
    "    SELECT ?x ?y WHERE {{\n",
    "      VALUES ?x {{ {vals} }}\n",
    "      ?x wdt:P2219 ?code . FILTER(strlen(?code)=2)\n",
    "      ?y wdt:P2219 ?code . FILTER(?x!=?y)\n",
    "    }}\"\"\"\n",
    "    for r in sparql(q):\n",
    "        msc_edges.append((r[\"x\"][\"value\"].split(\"/\")[-1],\n",
    "                          r[\"y\"][\"value\"].split(\"/\")[-1],\n",
    "                          \"MSC\"))\n",
    "    time.sleep(PAUSE)\n",
    "raw_edges.update(msc_edges)\n",
    "print(f\"✔ MSC edges: {len(msc_edges)}  (total {len(raw_edges)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————— Stage 6: build weighted graph\n",
    "WEIGHT = {\"P279\":1.0, \"P31\":1.0, \"MSC\":3.0}\n",
    "COLOR  = {\"P279\":\"#1f77b4\", \"P31\":\"#1f77b4\", \"MSC\":\"#2ca02c\"}\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for n in nodes:\n",
    "    G.add_node(n, label=labels.get(n,n))\n",
    "for p,c,prop in raw_edges:\n",
    "    if p in nodes and c in nodes:\n",
    "        G.add_edge(p,c,weight=WEIGHT[prop],color=COLOR[prop],prop=prop)\n",
    "\n",
    "print(f\"✔ graph: {G.number_of_nodes()} nodes | {G.number_of_edges()} edges\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
